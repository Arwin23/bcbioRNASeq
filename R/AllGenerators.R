# bcbioRNASeq ==================================================================
#' `bcbioRNASeq` Generator
#'
#' @family S4 Generators
#' @author Michael Steinbaugh, Lorena Pantano, Rory Kirchner, Victor Barrera
#' @export
#'
#' @description
#' Simply point to the final upload directory generated by
#' [bcbio](https://bcbio-nextgen.readthedocs.io/), and this constructor function
#' will take care of the rest. It automatically imports RNA-seq counts,
#' metadata, and the program versions used.
#'
#' @details
#' This class contains raw read counts and length-scaled
#' transcripts per million (TPM) generated by [tximport::tximport()]. Counts can
#' be loaded at gene or transcript level.
#'
#' @section Metadata:
#'
#' The [metadata()] slot contains:
#'
#' - Sample quality control metrics.
#' - Ensembl annotations.
#' - Server run paths.
#' - R session information (e.g. [utils::sessionInfo()]).
#'
#' @section Valid names:
#'
#' R is strict about values that are considered valid for use in [names()] and
#' [dimnames()] (i.e. [rownames()] and [colnames()]). Non-alphanumeric
#' characters, spaces, and **dashes** are not valid. Use either underscores or
#' periods in place of dashes when working in R. Also note that names should
#' **not begin with a number**, and will be prefixed with an `X` when sanitized.
#' Consult the documentation in the [base::make.names()] function for more
#' information. We strongly recommend adhering to these conventions when
#' labeling samples, to help avoid unexpected downstream behavior in R due to
#' [dimnames()] mismatches.
#'
#' @section Genome build:
#'
#' Ensure that the organism and genome build used with bcio match correctly
#' here in the function call. In particular, for the legacy *Homo sapiens*
#' GRCh37/hg19 genome build, ensure that `genomeBuild = "GRCh37"`. Otherwise,
#' the genomic ranges set in [rowRanges()] will mismatch. It is recommended
#' for current projects that GRCh38/hg38 is used in place of GRCh37/hg19
#' if possible.
#'
#' @section DESeq2:
#'
#' DESeq2 is run automatically when `bcbioRNASeq()` is called. Internally, this
#' automatically slots normalized counts into [assays()], and optionally
#' generates variance-stabilized `rlog` or `vst` counts, depending on the call.
#' When loading a dataset with a large number of samples (i.e. > 50), we
#' recommend disabling the `rlog` transformation, since it can take a long time
#' to compute.
#'
#' @section Remote data:
#'
#' When working in RStudio, we recommend connecting to the bcbio run directory
#' as a remote connection over
#' [sshfs](https://github.com/osxfuse/osxfuse/wiki/SSHFS). When loading a large
#' number of samples, it is preferable to call [bcbioRNASeq()] directly in R
#' on the remote server, if possible.
#'
#' @inheritParams basejump::makeSummarizedExperiment
#' @inheritParams general
#' @param uploadDir `string`. Path to final upload directory. This path is set
#'   when running "`bcbio_nextgen -w template`".
#' @param level `string`. Import counts at gene level ("`genes`"; *default*) or
#'   transcript level ("`transcripts`"; *advanced use*).
#' @param caller `string`. Expression caller:
#'   - "`salmon`" (*default*): [Salmon](https://combine-lab.github.io/salmon)
#'     alignment-free, quasi-mapped counts.
#'   - "`kallisto`". [Kallisto](https://pachterlab.github.io/kallisto)
#'     alignment-free, pseudo-aligned counts.
#'   - "`sailfish`".
#'     [Sailfish](http://www.cs.cmu.edu/~ckingsf/software/sailfish)
#'     alignment-free, lightweight counts.
#'   - "`star`": [STAR](https://github.com/alexdobin/STAR)
#'     (Spliced Transcripts Alignment to a Reference) aligned counts.
#'   - "`hisat2`": [HISAT2](https://ccb.jhu.edu/software/hisat2)
#'     (Hierarchical Indexing for Spliced Alignment of Transcripts) graph-based
#'     aligned counts.
#' @param samples `character` or `NULL`. Specify a subset of samples to load.
#'   The names must match the `description` specified in the bcbio YAML
#'   metadata. If a `sampleMetadataFile` is provided, that will take priority
#'   for sample selection. Typically this can be left unset.
#' @param censorSamples `character` or `NULL`. Samples to exclude from the
#'   analysis.
#' @param sampleMetadataFile `string` or `NULL`. Custom metadata file containing
#'   sample information. Otherwise defaults to sample metadata saved in the YAML
#'   file. Remote URLs are supported. Typically this can be left unset.
#' @param organism `string` or `NULL`. Organism name. Use the full Latin name
#'   (e.g. "Homo sapiens"), since this will be input downstream to AnnotationHub
#'   and ensembldb, unless `gffFile` is set. If left `NULL` (*not recommended*),
#'   the function call will skip loading gene/transcript-level annotations into
#'   [rowRanges()]. This can be useful for poorly annotation genomes or
#'   experiments involving multiple genomes.
#' @param genomeBuild `string` or `NULL`. Ensembl genome build name (e.g.
#'   "GRCh38"). This will be passed to AnnotationHub for `EnsDb` annotation
#'   matching, unless `gffFile` is set.
#' @param ensemblRelease `scalar integer` or `NULL`. Ensembl release version. If
#'   unset, defaults to current release, and does not typically need to be
#'   user-defined. Passed to AnnotationHub for `EnsDb` annotation matching,
#'   unless `gffFile` is set.
#' @param gffFile `string` or `NULL`. By default, we recommend leaving this
#'   `NULL` for genomes that are supported on Ensembl. In this case, the row
#'   annotations ([rowRanges()]) will be obtained automatically from Ensembl by
#'   passing the `organism`, `genomeBuild`, and `ensemblRelease` arguments to
#'   AnnotationHub and ensembldb. For a genome that is not supported on Ensembl
#'   and/or AnnotationHub, a GFF/GTF (General Feature Format) file is required.
#'   Generally, we recommend using a GTF (GFFv2) file here over a GFF3 file if
#'   possible, although all GFF formats are supported. The function will
#'   internally generate a `TxDb` containing transcript-to-gene mappings and
#'   construct a `GRanges` object containing the genomic ranges ([rowRanges()]).
#' @param vst `boolean`. Calculate variance-stabilizing transformation using
#'   [DESeq2::varianceStabilizingTransformation()]. Recommended by default
#'   for visualization.
#' @param rlog `boolean`. Calcualte regularized log transformation using
#'   [DESeq2::rlog()]. This calculation is slow for large datasets and now
#'   discouraged by default for visualization.
#'
#' @return `bcbioRNASeq`.
#'
#' @seealso
#' - `.S4methods(class = "bcbioRNASeq")`.
#' - [SummarizedExperiment::SummarizedExperiment()].
#' - [methods::initialize()].
#' - [methods::validObject()].
#' - [BiocGenerics::updateObject()].
#'
#' @examples
#' uploadDir <- system.file("extdata/bcbio", package = "bcbioRNASeq")
#'
#' # Gene level
#' object <- bcbioRNASeq(
#'     uploadDir = uploadDir,
#'     level = "genes",
#'     caller = "salmon",
#'     organism = "Mus musculus",
#'     ensemblRelease = 87L
#' )
#' show(object)
#' is(object, "RangedSummarizedExperiment")
#' validObject(object)
#'
#' # Transcript level
#' object <- bcbioRNASeq(
#'     uploadDir = uploadDir,
#'     level = "transcripts",
#'     caller = "salmon",
#'     organism = "Mus musculus",
#'     ensemblRelease = 87L
#' )
#' show(object)
#' validObject(object)
bcbioRNASeq <- function(
    uploadDir,
    level = c("genes", "transcripts"),
    caller = c("salmon", "kallisto", "sailfish", "star", "hisat2"),
    samples = NULL,
    censorSamples = NULL,
    sampleMetadataFile = NULL,
    organism = NULL,
    genomeBuild = NULL,
    ensemblRelease = NULL,
    gffFile = NULL,
    transgeneNames = NULL,
    spikeNames = NULL,
    vst = TRUE,
    rlog = FALSE,
    interestingGroups = "sampleName",
    ...
) {
    # Legacy arguments ---------------------------------------------------------
    # nocov start
    call <- match.call()
    # annotable
    if ("annotable" %in% names(call)) {
        stop("`annotable` is defunct. Consider using `gffFile` instead.")
    }
    # ensemblVersion
    if ("ensemblVersion" %in% names(call)) {
        warning("Use `ensemblRelease` instead of `ensemblVersion`.")
        ensemblRelease <- call[["ensemblVersion"]]
    }
    # organism
    if (!"organism" %in% names(call)) {
        message(paste(
            "`organism` is recommended for defining",
            "annotations in `rowRanges()`."
        ))
    }
    # transformationLimit
    if ("transformationLimit" %in% names(call)) {
        stop(paste(
            "`transformationLimit` is deprecated in favor of",
            "separate `vst` and `rlog` arguments."
        ))
    }
    rm(call)
    # nocov end

    # Assert checks ------------------------------------------------------------
    assert_is_a_string(uploadDir)
    assert_all_are_dirs(uploadDir)
    level <- match.arg(level)
    caller <- match.arg(caller)
    if (level == "transcripts") {
        assert_is_subset(caller, tximportCallers)
    }
    assert_is_any_of(samples, c("character", "NULL"))
    assert_is_any_of(censorSamples, c("character", "NULL"))
    assertIsAStringOrNULL(sampleMetadataFile)
    assertIsAStringOrNULL(organism)
    assertIsAnImplicitIntegerOrNULL(ensemblRelease)
    assertIsAStringOrNULL(genomeBuild)
    assert_is_any_of(transgeneNames, c("character", "NULL"))
    assert_is_any_of(spikeNames, c("character", "NULL"))
    assertIsAStringOrNULL(gffFile)
    if (is_a_string(gffFile)) {
        assert_all_are_existing_files(gffFile)
    }
    assert_is_a_bool(vst)
    assert_is_a_bool(rlog)
    assert_is_character(interestingGroups)

    # Directory paths ----------------------------------------------------------
    uploadDir <- normalizePath(uploadDir, winslash = "/", mustWork = TRUE)
    projectDir <- projectDir(uploadDir)
    sampleDirs <- sampleDirs(uploadDir)

    # Project summary YAML -----------------------------------------------------
    yamlFile <- file.path(projectDir, "project-summary.yaml")
    yaml <- import(yamlFile)
    assert_is_list(yaml)

    # bcbio run information ----------------------------------------------------
    dataVersions <-
        readDataVersions(file.path(projectDir, "data_versions.csv"))
    programVersions <-
        readProgramVersions(file.path(projectDir, "programs.txt"))
    bcbioLog <-
        readLog(file.path(projectDir, "bcbio-nextgen.log"))
    bcbioCommandsLog <-
        readLog(file.path(projectDir, "bcbio-nextgen-commands.log"))

    assert_is_tbl_df(dataVersions)
    assert_is_tbl_df(programVersions)
    assert_is_character(bcbioLog)
    assert_is_character(bcbioCommandsLog)

    # Sequencing lanes ---------------------------------------------------------
    lanes <- detectLanes(sampleDirs)
    assert_is_integer(lanes)

    # Determine which samples to load ------------------------------------------
    # Get the sample data.
    if (is_a_string(sampleMetadataFile)) {
        # User-defined external file.
        sampleData <- readSampleData(file = sampleMetadataFile, lanes = lanes)
    } else {
        # Automatic metadata from YAML file.
        sampleData <- readYAMLSampleData(file = yamlFile)
    }
    assert_is_subset(rownames(sampleData), names(sampleDirs))

    # Subset the sample directories, if necessary.
    if (is.character(samples) || is.character(censorSamples)) {
        # Matching against the YAML "description" input here.
        description <- as.character(sampleData[["description"]])
        assert_is_non_empty(description)
        if (is.character(samples)) {
            assert_is_subset(samples, description)
        } else {
            samples <- description
        }
        if (is.character(censorSamples)) {
            assert_is_subset(censorSamples, samples)
            samples <- setdiff(samples, censorSamples)
        }
        assert_is_non_empty(samples)
        sampleData <- filter(sampleData, !!sym("description") %in% !!samples)
    }
    samples <- rownames(sampleData)
    assert_is_subset(samples, names(sampleDirs))
    assertAllAreValidNames(samples)
    if (length(samples) < length(sampleDirs)) {
        message(paste(
            "Loading a subset of samples:",
            str_trunc(toString(samples), width = 80L),
            sep = "\n"
        ))
        allSamples <- FALSE
    } else {
        allSamples <- TRUE
    }
    sampleDirs <- sampleDirs[samples]

    # Column data --------------------------------------------------------------
    # Sample metrics. Note that sample metrics used for QC plots are not
    # currently generated when using fast RNA-seq workflow. This depends upon
    # MultiQC and aligned counts generated with STAR.
    colData <- readYAMLSampleMetrics(yamlFile)
    if (has_length(colData)) {
        assert_are_disjoint_sets(colnames(colData), colnames(sampleData))
        assert_is_subset(rownames(sampleData), rownames(colData))
        colData <- colData[rownames(sampleData), , drop = FALSE]
        colData <- cbind(colData, sampleData)
    } else {
        message("Fast mode detected. No metrics were calculated.")
        colData <- sampleData
    }
    assert_is_all_of(colData, "DataFrame")
    assert_are_identical(samples, rownames(colData))

    # Transcript-to-gene mappings ----------------------------------------------
    tx2geneFile <- file.path(projectDir, "tx2gene.csv")
    tx2gene <- readTx2gene(tx2geneFile)
    assert_is_all_of(tx2gene, "tx2gene")

    # Read counts --------------------------------------------------------------
    # Use tximport by default for transcript-aware callers.
    # Otherwise, resort to loading the featureCounts aligned counts data.
    if (caller %in% tximportCallers) {
        # tximport
        if (level == "transcripts") {
            txOut <- TRUE
        } else {
            txOut <- FALSE
        }
        txi <- .tximport(
            sampleDirs = sampleDirs,
            type = caller,
            txIn = TRUE,
            txOut = txOut,
            tx2gene = tx2gene
        )
        # `tpm` (abundance): transcripts per million.
        tpm <- txi[["abundance"]]
        # `counts`: raw counts
        counts <- txi[["counts"]]
        # Length: average transcript length.
        length <- txi[["length"]]
        # `countsFromAbundance`: `string` describing how TPMs were calculated.
        countsFromAbundance <- txi[["countsFromAbundance"]]
    } else if (caller %in% featureCountsCallers) {
        tpm <- NULL
        length <- NULL
        countsFromAbundance <- NULL
        # Load up the featureCounts aligned counts matrix.
        counts <- import(file = file.path(projectDir, "combined.counts"))
        assert_is_matrix(counts)
        colnames(counts) <- makeNames(colnames(counts))
        # Subset the combined matrix to match the samples.
        assert_is_subset(samples, colnames(counts))
        counts <- counts[, samples, drop = FALSE]
    }
    assert_are_identical(colnames(counts), rownames(colData))

    # Row data -----------------------------------------------------------------
    if (is_a_string(gffFile)) {
        message("Using `makeGRangesFromGFF()` for annotations.")
        rowRanges <- makeGRangesFromGFF(gffFile)
    } else if (is_a_string(organism)) {
        # Using AnnotationHub/ensembldb to obtain the annotations.
        message("Using `makeGRangesFromEnsembl()` for annotations.")
        rowRanges <- makeGRangesFromEnsembl(
            organism = organism,
            level = level,
            build = genomeBuild,
            release = ensemblRelease
        )
        if (is.null(genomeBuild)) {
            genomeBuild <- metadata(rowRanges)[["build"]]
        }
        if (is.null(ensemblRelease)) {
            ensemblRelease <- metadata(rowRanges)[["release"]]
        }
    } else {
        message("Unknown organism. Skipping annotations.")
        rowRanges <- emptyRanges(rownames(counts))
    }
    assert_is_all_of(rowRanges, "GRanges")

    # Gene-level variance stabilization ----------------------------------------
    if (level == "genes") {
        message(paste0(
            "Generating DESeqDataSet with DESeq2 ",
            packageVersion("DESeq2"), "..."
        ))
        if (is.list(txi)) {
            # Create `DESeqDataSet` from `tximport()` return `list` by default.
            # Note that we're setting an empty design formula here.
            dds <- DESeqDataSetFromTximport(
                txi = txi,
                colData = colData,
                design = ~ 1L
            )
        } else {
            # Otherwise fall back to creating from the counts matrix.
            # This applies to datasets using aligned counts (e.g. STAR).
            dds <- DESeqDataSetFromMatrix(
                countData = counts,
                colData = colData,
                design = ~ 1L
            )
        }
        # Skip full DESeq2 calculations, for internal bcbio test data.
        if (.dataHasVariation(dds)) {
            # Suppress expected warnings about the design formula.
            dds <- suppressWarnings(DESeq(dds))
            if (isTRUE(vst)) {
                message("Applying variance-stabilizing transformation...")
                vst <- assay(varianceStabilizingTransformation(dds))
            } else {
                vst <- NULL
            }
            if (isTRUE(rlog)) {
                message("Applying regularized log transformation...")
                rlog <- assay(rlog(dds))
            } else {
                rlog <- NULL
            }
        } else {
            # This step is covered by the bcbio pipeline tests.
            # nocov start
            warning("Data has no variation. Skipping transformations.")
            dds <- estimateSizeFactors(dds)
            vst <- NULL
            rlog <- NULL
            # nocov end
        }
        normalized <- counts(dds, normalized = TRUE)
    } else if (level == "transcripts") {
        normalized <- NULL
        vst <- NULL
        rlog <- NULL
    }

    # Assays -------------------------------------------------------------------
    assays <- list(
        counts = counts,
        tpm = tpm,
        length = length,
        normalized = normalized,
        vst = vst,
        rlog = rlog
    )

    # Metadata -----------------------------------------------------------------
    # TODO Make this a function in bcbioBase.
    # Run date and template name.
    match <- str_match(
        string = basename(projectDir),
        pattern = projectDirPattern
    )
    date <- as.Date(match[[2L]])
    template <- match[[3L]]
    rm(match)

    # Interesting groups.
    interestingGroups <- camel(interestingGroups)
    assert_is_subset(interestingGroups, colnames(colData))

    metadata <- list(
        version = packageVersion,
        level = level,
        caller = caller,
        countsFromAbundance = countsFromAbundance,
        uploadDir = uploadDir,
        sampleDirs = sampleDirs,
        sampleMetadataFile = as.character(sampleMetadataFile),
        projectDir = projectDir,
        template = template,
        runDate = runDate,
        interestingGroups = interestingGroups,
        organism = as.character(organism),
        genomeBuild = as.character(genomeBuild),
        ensemblRelease = as.integer(ensemblRelease),
        gffFile = as.character(gffFile),
        tx2gene = tx2gene,
        lanes = lanes,
        yaml = yaml,
        dataVersions = dataVersions,
        programVersions = programVersions,
        bcbioLog = bcbioLog,
        bcbioCommandsLog = bcbioCommandsLog,
        allSamples = allSamples,
        call = match.call()
    )

    # Return -------------------------------------------------------------------
    .new.bcbioRNASeq(
        assays = assays,
        rowRanges = rowRanges,
        colData = colData,
        metadata = metadata,
        transgeneNames = transgeneNames,
        spikeNames = spikeNames
    )
}



.new.bcbioRNASeq <-  # nolint
    function(
        assays,
        rowRanges,
        colData,
        metadata,
        transgeneNames = NULL,
        spikeNames = NULL
    ) {
        new(
            Class = "bcbioRNASeq",
            makeSummarizedExperiment(
                assays = assays,
                rowRanges = rowRanges,
                colData = colData,
                metadata = metadata,
                transgeneNames = transgeneNames,
                spikeNames = spikeNames
            )
        )
    }



# Used for bcbio pipeline checks.
.dataHasVariation <- function(dds) {
    !all(rowSums(assay(dds) == assay(dds)[, 1L]) == ncol(dds))
}



# DESeqAnalysis ================================================================
#' `DESeqAnalysis` Generator
#'
#' @family S4 Generators
#' @author Michael Steinbaugh
#' @export
#'
#' @param data `DESeqDataSet`.
#' @param transform `DESeqTransform`.
#' @param results `list`. One or more unshrunken `DESeqResults`. Assign the
#'   [DESeq2::results()] return here.
#' @param lfcShrink `list`. One or more shrunken `DESeqResults`. Assign the
#'   [DESeq2::lfcShrink()] return here.
#'
#' @return `DESeqAnalysis`.
#'
#' @examples
#' library(DESeq2)
#' dds <- as(bcb_small, "DESeqDataSet")
#' design(dds) <- ~ treatment
#' dds <- DESeq(dds)
#' class(dds)
#' vst <- varianceStabilizingTransformation(dds)
#' class(vst)
#' resultsNames(dds)
#' res <- results(dds, name = resultsNames(dds)[[2L]])
#' class(res)
#' x <- DESeqAnalysis(
#'     data = dds,
#'     transform = vst,
#'     results = list(res),
#'     lfcShrink = list(lfcShrink(dds = dds, coef = 2L))
#' )
#' print(x)
DESeqAnalysis <- function(
    data,
    transform,
    results,
    lfcShrink
) {
    new(
        Class = "DESeqAnalysis",
        data = data,
        transform = transform,
        results = results,
        lfcShrink = lfcShrink
    )
}



# DESeqResultsTables ===========================================================
#' DESeq2 Differential Expression Results Tables
#'
#' @note Log fold change cutoff threshold ("`lfcThreshold`") does not apply to
#'   statistical hypothesis testing, only gene filtering in the results tables.
#'   See [DESeq2::results()] for additional information about using
#'   `lfcThreshold` and `altHypothesis` to set an alternative hypothesis based
#'   on expected fold changes.
#'
#' @name DESeqResultsTables
#' @family S4 Generators
#' @author Michael Steinbaugh
#' @include AllGenerics.R
#' @export
#'
#' @inheritParams general
#' @param rowData `boolean`. Include gene annotations.
#' @param counts `boolean`. Include DESeq2 normalized counts.
#'
#' @return `DESeqResultsTables`.
#'
#' @seealso
#' - [markdown()].
#' - [write()].
#'
#' @examples
#' # DESeqAnalysis ====
#' # This is the recommended default method.
#' x <- DESeqResultsTables(deseq_small)
#' print(x)
#'
#' # DESeqResults ====
#' res <- as(deseq_small, "DESeqResults")
#' x <- DESeqResultsTables(res)
#' print(x)
NULL



.DESeqResultsTables.DESeqResults <-  # nolint
    function(object) {
        validObject(object)
        assert_is_all_of(object, "DESeqResults")
        assert_is_subset(c("log2FoldChange", "padj"), colnames(object))
        alpha <- metadata(object)[["alpha"]]
        assert_is_a_number(alpha)
        lfcThreshold <- metadata(object)[["lfcThreshold"]]
        assert_is_a_number(lfcThreshold)

        # Set LFC and test (P value) columns.
        lfcCol <- "log2FoldChange"
        testCol <- "padj"
        lfc <- sym(lfcCol)
        test <- sym(testCol)
        assert_is_subset(
            x = c(lfcCol, testCol),
            y = colnames(object)
        )

        # DEG tables are sorted by adjusted P value.
        deg <- object %>%
            as_tibble(rownames = "rowname") %>%
            # Remove genes without an adjusted P value.
            filter(!is.na(!!test)) %>%
            # Remove genes that don't pass alpha cutoff.
            filter(!!test < !!alpha) %>%
            # Arrange by adjusted P value.
            arrange(!!test) %>%
            # Remove genes that don't pass LFC threshold.
            filter(!!lfc > !!lfcThreshold | !!lfc < -UQ(lfcThreshold))
        # Get directional subsets.
        degUp <- filter(deg, !!lfc > 0L)
        degDown <- filter(deg, !!lfc < 0L)

        new(
            Class = "DESeqResultsTables",
            all = object,
            deg = as(deg, "DataFrame"),
            degUp = as(degUp, "DataFrame"),
            degDown = as(degDown, "DataFrame")
        )
    }



.DESeqResultsTables.DESeqAnalysis <-  # nolint
    function(
        object,
        results,
        lfcShrink = TRUE,
        rowData = TRUE,
        counts = TRUE
    ) {
        validObject(object)
        assert_is_a_bool(rowData)
        assert_is_a_bool(counts)

        # Match the DESeqResults object.
        results <- .matchResults(
            object = object,
            results = results,
            lfcShrink = lfcShrink
        )

        # Add columns (optional) -----------------------------------------------
        if (
            isTRUE(rowData) ||
            isTRUE(counts)
        ) {
            # Coerce to `DataFrame`.
            # We'll regenerate a modified `DESeqResults` from this below.
            data <- as(results, "DataFrame")

            # Row annotations
            if (isTRUE(rowData)) {
                message(paste(
                    "Adding `rowData()` annotations (atomic columns only)..."
                ))
                rowData <- sanitizeRowData(rowData(object@data))
                # DESeq2 includes additional information in `rowData()` that
                # isn't informative for a user, and doesn't need to be included
                # in the CSV. Use our `bcb_small` example dataset to figure out
                # which columns are worth including.
                keep <- intersect(
                    x = colnames(rowData),
                    y = colnames(rowData(bcbioRNASeq::bcb_small))
                )
                rowData <- rowData[, keep, drop = FALSE]
                assert_all_are_true(vapply(rowData, is.atomic, logical(1L)))
                assert_is_non_empty(rowData)
                assert_are_disjoint_sets(colnames(data), colnames(rowData))
                data <- cbind(data, rowData)
            }

            # DESeq2 normalized counts
            if (isTRUE(counts)) {
                message("Adding DESeq2 normalized counts...")
                counts <- counts(object@data, normalized = TRUE)
                assert_are_disjoint_sets(colnames(data), colnames(counts))
                assert_are_identical(rownames(data), rownames(counts))
                data <- cbind(data, counts)
            }

            # Regenerate the DESeqResults.
            results <- DESeqResults(
                DataFrame = data,
                priorInfo = priorInfo(results)
            )
        }

        # Return ---------------------------------------------------------------
        DESeqResultsTables(results)
    }



#' @rdname DESeqResultsTables
#' @export
setMethod(
    f = "DESeqResultsTables",
    signature = signature("DESeqResults"),
    definition = .DESeqResultsTables.DESeqResults
)



#' @rdname DESeqResultsTables
#' @export
setMethod(
    f = "DESeqResultsTables",
    signature = signature("DESeqAnalysis"),
    definition = .DESeqResultsTables.DESeqAnalysis
)
